{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ca1d87a",
   "metadata": {},
   "source": [
    "### Autoencoder intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c6f666d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.empenhos_df import EMPENHOS\n",
    "    \n",
    "ds_train = EMPENHOS(\n",
    "    train=True, testing_mode=True\n",
    ")  # training dataset\n",
    "ds_val = EMPENHOS(\n",
    "    train=False, testing_mode=True\n",
    ")  # evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "139994fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptsdae.sdae import StackedDenoisingAutoEncoder\n",
    "\n",
    "\n",
    "# dimensão de input: 387\n",
    "# dimensão latente: 10\n",
    "autoencoder = StackedDenoisingAutoEncoder(\n",
    "        [387, 1000, 2000, 2000, 10], final_activation=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c39785a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (linear): Linear(in_features=387, out_features=1000, bias=True)\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (linear): Linear(in_features=1000, out_features=2000, bias=True)\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (linear): Linear(in_features=2000, out_features=2000, bias=True)\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (linear): Linear(in_features=2000, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f485d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (linear): Linear(in_features=10, out_features=2000, bias=True)\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (linear): Linear(in_features=2000, out_features=2000, bias=True)\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (linear): Linear(in_features=2000, out_features=1000, bias=True)\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (linear): Linear(in_features=1000, out_features=387, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb732042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 387])\n",
      "torch.Size([1000])\n",
      "torch.Size([2000, 1000])\n",
      "torch.Size([2000])\n",
      "torch.Size([2000, 2000])\n",
      "torch.Size([2000])\n",
      "torch.Size([10, 2000])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for param in autoencoder.encoder.parameters():\n",
    "    print(param.shape) # temos 8 tensors para um encoder que possui 4 camadas: [387, 1000, 2000, 2000, 10]\n",
    "    \n",
    "# formato:\n",
    "# Weight shape: [out_features, in_features]\n",
    "# Bias shape: [out_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f4b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(autoencoder.parameters())[0] \n",
    "\n",
    "# weights e bias inicializados da seguinte forma:\n",
    "\n",
    "# nn.init.xavier_uniform_(weight, gain) -> Fills the weight tensor with values sampled from a uniform distribution (gain é um fator escalar: sqrt[2])\n",
    "# nn.init.constant_(bias, 0) -> Seta todos os bias com valor 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "61874743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "dataloader = DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=10,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "validation_loader = DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=10,\n",
    "        shuffle=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44358b64",
   "metadata": {},
   "source": [
    "### Função de Predict (SAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "20fff7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT FUNCTION\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "def predict(\n",
    "    dataset: torch.utils.data.Dataset,\n",
    "    model: torch.nn.Module,\n",
    "    batch_size: int,\n",
    "    cuda: bool = True,\n",
    "    silent: bool = False,\n",
    "    encode: bool = True,\n",
    ") -> torch.Tensor:\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, pin_memory=False, shuffle=False\n",
    "    )\n",
    "    data_iterator = tqdm(dataloader, leave=False, unit=\"batch\", disable=silent)\n",
    "    features = []\n",
    "    \n",
    "    \n",
    "    if isinstance(model, torch.nn.Module): # se existir model, True\n",
    "        model.eval() # porque isso?\n",
    "        \n",
    "        \n",
    "        \n",
    "    for batch in data_iterator:\n",
    "        if isinstance(batch, tuple) or isinstance(batch, list) and len(batch) in [1, 2]:\n",
    "            batch = batch[0]\n",
    "\n",
    "        \n",
    "        batch = batch.squeeze(1).view(batch.size(0), -1)\n",
    "        if encode:\n",
    "            output = model.encode(batch)\n",
    "        else:\n",
    "            output = model(batch)\n",
    "        features.append(\n",
    "            output.detach().cpu()\n",
    "        )  # move to the CPU to prevent out of memory on the GPU\n",
    "    return torch.cat(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8441fb8",
   "metadata": {},
   "source": [
    "### Função de Train (SAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d2be6495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "def train(\n",
    "    dataset: torch.utils.data.Dataset,\n",
    "    autoencoder: torch.nn.Module,\n",
    "    epochs: int,\n",
    "    batch_size: int,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scheduler: Any = None,\n",
    "    validation: Optional[torch.utils.data.Dataset] = None,\n",
    "    corruption: Optional[float] = None,\n",
    "    cuda: bool = True,\n",
    "    sampler: Optional[torch.utils.data.sampler.Sampler] = None,\n",
    "    silent: bool = False,\n",
    "    update_freq: Optional[int] = 1,\n",
    "    update_callback: Optional[Callable[[float, float], None]] = None,\n",
    "    num_workers: Optional[int] = None,\n",
    "    epoch_callback: Optional[Callable[[int, torch.nn.Module], None]] = None,\n",
    ") -> None:\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=False,\n",
    "        sampler=sampler,\n",
    "        shuffle=True if sampler is None else False,\n",
    "        num_workers=num_workers if num_workers is not None else 0,\n",
    "    )\n",
    "    if validation is not None:\n",
    "        validation_loader = DataLoader(\n",
    "            validation,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "    else:\n",
    "        validation_loader = None\n",
    "    loss_function = nn.MSELoss()\n",
    "    validation_loss_value = -1\n",
    "    loss_value = 0\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        data_iterator = tqdm(\n",
    "            dataloader,\n",
    "            leave=True,\n",
    "            unit=\"batch\",\n",
    "            postfix={\"epo\": epoch, \"lss\": \"%.6f\" % 0.0, \"vls\": \"%.6f\" % -1,},\n",
    "            disable=silent,\n",
    "        )\n",
    "        for index, batch in enumerate(data_iterator):\n",
    "            autoencoder.train()\n",
    "            if (\n",
    "                isinstance(batch, tuple)\n",
    "                or isinstance(batch, list)\n",
    "                and len(batch) in [1, 2]\n",
    "            ):\n",
    "                batch = batch[0] # retornar sem as labels (se existirem)\n",
    "                \n",
    "            # run the batch through the autoencoder and obtain the output\n",
    "            if corruption is not None:\n",
    "                output = autoencoder(F.dropout(batch, corruption))\n",
    "            else:\n",
    "                output = autoencoder(batch)\n",
    "                \n",
    "            # Somente o primeiro batch\n",
    "            if index == 0 and epoch==0:\n",
    "                print(f\"\\nOutput of AE (shape: {output.shape})\") # o output do autoencoder deve ter as mesmas dimensões que a de entrada\n",
    "            \n",
    "            \n",
    "            loss = loss_function(output, batch)\n",
    "\n",
    "            loss_value = float(loss.item())\n",
    "            optimizer.zero_grad() # clears (resets) all the gradients of the model's parameters that were accumulated in the previous backward pass. \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            data_iterator.set_postfix( # adicionando os stats de treinamento para visualização em tempo real\n",
    "                epo=epoch, lss=\"%.6f\" % loss_value, vls=\"%.6f\" % validation_loss_value,\n",
    "            )\n",
    "        \n",
    "        \n",
    "        # AVALIAÇÃO DO MODELO\n",
    "        autoencoder.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for val_batch in validation_loader:\n",
    "                if isinstance(val_batch, (tuple, list)) and len(val_batch) in [1, 2]:\n",
    "                    val_batch = val_batch[0]\n",
    "                val_output = autoencoder(val_batch)\n",
    "                val_loss = loss_function(val_output, val_batch)\n",
    "                val_losses.append(val_loss.item())\n",
    "        mean_val_loss = sum(val_losses) / len(val_losses)\n",
    "        print(f\"Validation loss: {mean_val_loss:.6f}\")\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fc57fc",
   "metadata": {},
   "source": [
    "### Função de pre-training (SAE)\n",
    "\n",
    "Nessa etapa, fazemos uma iteração para cada camada do SAE e treinamos o modelo a codificar e decodificar em cada camada. Em seguida, os parâmetros são copiados para o SAE original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8a50d3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0\n",
      "387\n",
      "1000\n",
      "DenoisingAutoencoder(\n",
      "  (activation): ReLU()\n",
      "  (corruption): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "torch.Size([1000, 387])\n",
      "torch.Size([387, 1000])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from ptsdae.dae import DenoisingAutoencoder\n",
    "from ptsdae.sdae import StackedDenoisingAutoEncoder\n",
    "\n",
    "\n",
    "# PRETRAIN FUNC\n",
    "\n",
    "corruption = 0.2\n",
    "optimizer=lambda model: SGD(model.parameters(), lr=0.1, momentum=0.9) #  it means the current update is made of 90% of the previous update (momentum) and 10% of the new gradient\n",
    "scheduler=lambda x: StepLR(x, 100, gamma=0.1)\n",
    "current_dataset = ds_train\n",
    "current_validation = ds_val\n",
    "number_of_subautoencoders = len(autoencoder.dimensions) - 1\n",
    "\n",
    "for index in range(number_of_subautoencoders): # 4 subautoencoders\n",
    "    \n",
    "    encoder, decoder = autoencoder.get_stack(index)\n",
    "    # index = 0: [encoder from input_dim → 1000] e [decoder from 1000 → input_dim]\n",
    "    # index = 1: [encoder from 1000 → 2000] e [decoder from 2000 → 1000]\n",
    "    \n",
    "    # autoencoder.dimensions = [input_dim, 1000, 2000, 2000, num_clusters]\n",
    "    # index = 0: embedding_dimension: [input_dim] e hidden_dimension: [1000]\n",
    "    embedding_dimension = autoencoder.dimensions[index]\n",
    "    hidden_dimension = autoencoder.dimensions[index + 1]\n",
    "    \n",
    "    \n",
    "    # manual override to prevent corruption for the last subautoencoder\n",
    "    if index == (number_of_subautoencoders - 1):\n",
    "        corruption = None\n",
    "        \n",
    "        \n",
    "    # initialise the subautoencoder\n",
    "    # Representa uma camada do SAE\n",
    "    sub_autoencoder = DenoisingAutoencoder(\n",
    "        embedding_dimension=embedding_dimension,\n",
    "        hidden_dimension=hidden_dimension,\n",
    "        activation=torch.nn.ReLU() if index != (number_of_subautoencoders - 1) else None,\n",
    "        corruption=nn.Dropout(corruption) if corruption is not None else None,\n",
    "    )\n",
    "    \n",
    "    # Corruption serve para o modelo aprender a reconstruir as features e não memorizar inputs\n",
    "    # assim, durante o treinamento, o modelo reconstruindo os dados originais e não corrompidos.\n",
    "\n",
    "    if index == 0:\n",
    "        print(f\"index: {index}\")\n",
    "        print(embedding_dimension)\n",
    "        print(hidden_dimension)\n",
    "        print(sub_autoencoder)\n",
    "        print(sub_autoencoder.encoder_weight.shape)\n",
    "        print(sub_autoencoder.decoder_weight.shape)\n",
    "    \n",
    "    ae_optimizer = optimizer(sub_autoencoder)\n",
    "    ae_scheduler = scheduler(ae_optimizer) if scheduler is not None else scheduler\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95f3dea",
   "metadata": {},
   "source": [
    "#### Pretrain completa:\n",
    "treinamento de 20 épocas para cada camada do autoencoder (sub_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a26bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0\n",
      "387\n",
      "1000\n",
      "DenoisingAutoencoder(\n",
      "  (activation): ReLU()\n",
      "  (corruption): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "\n",
      "Output of AE (shape: torch.Size([10, 387]))\n",
      "Validation loss: 0.024787\n",
      "Validation loss: 0.018079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\parai\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.013258\n",
      "Validation loss: 0.010336\n",
      "Validation loss: 0.008591\n",
      "Validation loss: 0.007457\n",
      "Validation loss: 0.006591\n",
      "Validation loss: 0.006010\n",
      "Validation loss: 0.005489\n",
      "Validation loss: 0.005096\n",
      "Validation loss: 0.004747\n",
      "Validation loss: 0.004451\n",
      "Validation loss: 0.004246\n",
      "Validation loss: 0.004014\n",
      "Validation loss: 0.003837\n",
      "Validation loss: 0.003668\n",
      "Validation loss: 0.003526\n",
      "Validation loss: 0.003396\n",
      "Validation loss: 0.003269\n",
      "Validation loss: 0.003157\n",
      "Treinamento feito para camada 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output of AE (shape: torch.Size([10, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.007170\n",
      "Validation loss: 0.006500\n",
      "Validation loss: 0.005854\n",
      "Validation loss: 0.005273\n",
      "Validation loss: 0.004801\n",
      "Validation loss: 0.004431\n",
      "Validation loss: 0.004109\n",
      "Validation loss: 0.003847\n",
      "Validation loss: 0.003622\n",
      "Validation loss: 0.003440\n",
      "Validation loss: 0.003267\n",
      "Validation loss: 0.003128\n",
      "Validation loss: 0.002997\n",
      "Validation loss: 0.002879\n",
      "Validation loss: 0.002784\n",
      "Validation loss: 0.002692\n",
      "Validation loss: 0.002607\n",
      "Validation loss: 0.002532\n",
      "Validation loss: 0.002457\n",
      "Validation loss: 0.002394\n",
      "Treinamento feito para camada 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output of AE (shape: torch.Size([10, 2000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.002791\n",
      "Validation loss: 0.002669\n",
      "Validation loss: 0.002541\n",
      "Validation loss: 0.002418\n",
      "Validation loss: 0.002304\n",
      "Validation loss: 0.002202\n",
      "Validation loss: 0.002105\n",
      "Validation loss: 0.002023\n",
      "Validation loss: 0.001948\n",
      "Validation loss: 0.001878\n",
      "Validation loss: 0.001814\n",
      "Validation loss: 0.001755\n",
      "Validation loss: 0.001702\n",
      "Validation loss: 0.001651\n",
      "Validation loss: 0.001607\n",
      "Validation loss: 0.001565\n",
      "Validation loss: 0.001526\n",
      "Validation loss: 0.001489\n",
      "Validation loss: 0.001455\n",
      "Validation loss: 0.001423\n",
      "Treinamento feito para camada 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output of AE (shape: torch.Size([10, 2000]))\n",
      "Validation loss: 0.000590\n",
      "Validation loss: 0.000585\n",
      "Validation loss: 0.000579\n",
      "Validation loss: 0.000573\n",
      "Validation loss: 0.000568\n",
      "Validation loss: 0.000562\n",
      "Validation loss: 0.000557\n",
      "Validation loss: 0.000551\n",
      "Validation loss: 0.000546\n",
      "Validation loss: 0.000541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.000537\n",
      "Validation loss: 0.000532\n",
      "Validation loss: 0.000528\n",
      "Validation loss: 0.000524\n",
      "Validation loss: 0.000520\n",
      "Validation loss: 0.000516\n",
      "Validation loss: 0.000512\n",
      "Validation loss: 0.000509\n",
      "Validation loss: 0.000505\n",
      "Validation loss: 0.000502\n",
      "Treinamento feito para camada 3\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import TensorDataset\n",
    "from ptsdae.dae import DenoisingAutoencoder\n",
    "\n",
    "\n",
    "# PRETRAIN FUNC\n",
    "\n",
    "corruption = 0.2\n",
    "optimizer=lambda model: SGD(model.parameters(), lr=0.1, momentum=0.9) #  it means the current update is made of 90% of the previous update (momentum) and 10% of the new gradient\n",
    "scheduler=lambda x: StepLR(x, 100, gamma=0.1)\n",
    "current_dataset = ds_train\n",
    "current_validation = ds_val\n",
    "number_of_subautoencoders = len(autoencoder.dimensions) - 1\n",
    "\n",
    "for index in range(number_of_subautoencoders): # 4 subautoencoders\n",
    "    \n",
    "    encoder, decoder = autoencoder.get_stack(index)\n",
    "    # index = 0: [encoder from input_dim → 1000] e [decoder from 1000 → input_dim]\n",
    "    # index = 1: [encoder from 1000 → 2000] e [decoder from 2000 → 1000]\n",
    "    \n",
    "    # autoencoder.dimensions = [input_dim, 1000, 2000, 2000, num_clusters]\n",
    "    # index = 0: embedding_dimension: [input_dim] e hidden_dimension: [1000]\n",
    "    embedding_dimension = autoencoder.dimensions[index]\n",
    "    hidden_dimension = autoencoder.dimensions[index + 1]\n",
    "    \n",
    "    \n",
    "    # manual override to prevent corruption for the last subautoencoder\n",
    "    if index == (number_of_subautoencoders - 1):\n",
    "        corruption = None\n",
    "        \n",
    "        \n",
    "    # initialise the subautoencoder\n",
    "    # retorna o objeto sub_autoencoder\n",
    "    # [Input] → 1000 → 2000 → 2000 → [num_clusters] --> SÃO 4 TRANSIÇÕES\n",
    "    # sub-autoencoder = one encoder layer + one decoder layer trained to reconstruct its input\n",
    "    sub_autoencoder = DenoisingAutoencoder( # \n",
    "        embedding_dimension=embedding_dimension,\n",
    "        hidden_dimension=hidden_dimension,\n",
    "        activation=torch.nn.ReLU() if index != (number_of_subautoencoders - 1) else None,\n",
    "        corruption=nn.Dropout(corruption) if corruption is not None else None,\n",
    "    )\n",
    "\n",
    "    ae_optimizer = optimizer(sub_autoencoder)\n",
    "    ae_scheduler = scheduler(ae_optimizer) if scheduler is not None else scheduler\n",
    "    \n",
    "    # TREINAMENTO POR CAMADA do SAE\n",
    "    # no index = 0, modelo irá aprender a codificar: [n_samples, 387] -> [n_samples, 1000]\n",
    "    # e a decodificar: [n_samples, 1000] -> [n_samples, 387]\n",
    "    train(\n",
    "        current_dataset,\n",
    "        sub_autoencoder,\n",
    "        epochs=20,\n",
    "        batch_size=10,\n",
    "        optimizer=ae_optimizer,\n",
    "        validation=current_validation,\n",
    "        corruption=None,  # already have dropout in the DAE !! (mas porque?)\n",
    "        scheduler=ae_scheduler,\n",
    "        cuda=False,\n",
    "        sampler=None,\n",
    "        silent=True,\n",
    "    )\n",
    "    # copiar os pesos adquiridos no treinamento acima para o encoder e decoder do SAE instanciado anteriormente\n",
    "    sub_autoencoder.copy_weights(encoder, decoder)\n",
    "    \n",
    "    print(f\"Treinamento feito para camada {index}\")\n",
    "    \n",
    "    # current_dataset e current_validation são substituídos completamente pelo que o sub_autoencoder[index] prediziu\n",
    "    # note que: ele está fazendo somente o encode iterativamente.\n",
    "    # note também que: dentro de predict(), muda-se o modelo para modo .eval()\n",
    "    if index != (number_of_subautoencoders - 1):\n",
    "        current_dataset = TensorDataset(\n",
    "            predict(\n",
    "                current_dataset,\n",
    "                sub_autoencoder,\n",
    "                batch_size=10,\n",
    "                cuda=False,\n",
    "                silent=False,\n",
    "            )\n",
    "        )\n",
    "        if current_validation is not None:\n",
    "            current_validation = TensorDataset(\n",
    "                predict(\n",
    "                    current_validation,\n",
    "                    sub_autoencoder,\n",
    "                    batch_size=10,\n",
    "                    cuda=False,\n",
    "                    silent=False,\n",
    "                )\n",
    "            )\n",
    "    else: # Não entendi porque é designado None, no final de contas\n",
    "        current_dataset = None\n",
    "        current_validation = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c28361",
   "metadata": {},
   "source": [
    "### Após o Pretraining, aplicamos o Train de fato\n",
    "\n",
    "Vamos reaproveitar a função train já implementada anteriormente para fazer um treinamento de 20 épocas sobre o objeto SAE (StackedAutoEncoder) completo (não será feito treinamento por camadas como no pretreino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f4c1dcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "\n",
      "Output of AE (shape: torch.Size([10, 387]))\n",
      "Validation loss: 0.009188\n",
      "Validation loss: 0.009188\n",
      "Validation loss: 0.009188\n",
      "Validation loss: 0.009188\n",
      "Validation loss: 0.009188\n",
      "Validation loss: 0.009188\n",
      "Validation loss: 0.009188\n",
      "Validation loss: 0.009188\n",
      "Validation loss: 0.009188\n",
      "Validation loss: 0.009188\n",
      "Validation loss: 0.009188\n",
      "Validation loss: 0.009188\n",
      "Validation loss: 0.009188\n",
      "Validation loss: 0.009188\n",
      "Validation loss: 0.009188\n",
      "Validation loss: 0.009188\n",
      "Validation loss: 0.009188\n",
      "Validation loss: 0.009188\n",
      "Validation loss: 0.009188\n",
      "Validation loss: 0.009188\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    ds_train,\n",
    "    autoencoder,\n",
    "    cuda=False,\n",
    "    validation=ds_val,\n",
    "    epochs=20,\n",
    "    batch_size=10,\n",
    "    optimizer=ae_optimizer,\n",
    "    scheduler=StepLR(ae_optimizer, 100, gamma=0.1),\n",
    "    corruption=0.2,\n",
    "    silent=True\n",
    ")\n",
    "\n",
    "# Como o dataset é minúsculo, o modelo está em regime de overfitting e possui validation loss muito pequeno e constante\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
