csv_path: 'tce_fit.csv'
parquet_path: 'data/tce.parquet'
vector_store_dir: 'data/chroma_db'

output_dir: 'output_parquets'
output_embeddings: 'embeds'
output_predicted_dir: 'outputs/features'
saved_models_dir: 'outputs/models'
saved_models_sorted_dir: 'outputs/models_sorted'

# Embedding model config
embedding_model: 'sentence-transformers/all-MiniLM-L12-v1' # sentence-transformers/all-MiniLM-L12-v1 // sentence-transformers/facebook-dpr-ctx_encoder-multiset-base // tomaarsen/static-similarity-mrl-multilingual-v1
embedding_batch_size: 128 # computaçao paralela para fazer os embeddings
batch_size: 512


# Autoencoder
batch_size_models: 256
pretrain_epochs: 50
finetune_epochs: 100
input_dim: 387  # Your embedding dimension (dimensão da variável X)
hidden_layer: 10

# DEC config
num_clusters_testing: 10
num_clusters: 56 # numero otimal de clusters, encontrado através do elbow method
optimal_ks_by_elem: [
  94,
  58,
  58,
  3,
  58,
  27,
  57,
  4,
  56,
  57,
  57,
  5,
  58,
  2,
  57,
  53,
  58,
  58,
  58,
  57,
  55,
  13,
  3,
  56,
  57,
  58,
  4,
  57,
  58,
  3,
  14,
  57,
  58,
  58,
  6,
  57,
  57,
  58,
  13,
  13,
  3,
  14,
  3,
  3,
  54,
  58,
  13,
  3,
  13,
  2,
  15,
  57,
  17,
  17,
  2,
  1,
  2,
  4,
  58,
  2,
  12,
  13,
  13,
  58,
  13,
  13,
  2,
  3,
  2,
  2,
  17,
  13,
  13,
  14,
  58,
  7,
  12,
  2,
  13,
  17,
  13,
  13,
  5,
  6,
  13,
  1,
  2,
  11,
  5,
  3,
  2,
  3,
  8,
  1,
  12,
  2,
  3,
  11,
  1,
  13,
  5,
  13,
  2,
  1,
  2,
  5,
  1,
  2,
  3,
  13,
  5,
  2,
  5,
  2,
  1,
  1,
  8,
  1,
  1,
  1,
  1,
  3,
  5,
  1,
  12,
  12,
  1,
  2,
  1
]
epochs_dec: 100
epochs_dec_elem: 10 ###
lr_DEC_opt: 0.0004