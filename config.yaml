csv_path: 'tce_fit.csv'
parquet_path: 'data/tce.parquet'
vector_store_dir: 'data/chroma_db'

output_dir: 'output_parquets'
output_embeddings: 'embeds'
output_predicted_dir: 'outputs/features'
saved_models_dir: 'outputs/models'
saved_models_sorted_dir: 'outputs/models_sorted'

# Embedding model config
embedding_model: 'sentence-transformers/all-MiniLM-L12-v1' # sentence-transformers/all-MiniLM-L12-v1 // sentence-transformers/facebook-dpr-ctx_encoder-multiset-base // tomaarsen/static-similarity-mrl-multilingual-v1
embedding_batch_size: 128 # computaçao paralela para fazer os embeddings
batch_size: 512


# Autoencoder
batch_size_models: 256
pretrain_epochs: 50
finetune_epochs: 100
input_dim: 387  # Your embedding dimension (dimensão da variável X)
hidden_layer: 10

# DEC config
num_clusters_testing: 10
num_clusters: 75 
optimal_ks_by_elem: [
  2,
  2,
  2,
  2,
  2,
  2,
  2,
  2,
  2,
  2,
  2,
  1,
  1,
  1,
  2,
  1,
  1,
  2,
  2,
  6,
  1,
  6,
  2,
  1,
  1,
  1,
  2,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  2,
  1,
  1,
  2,
  1,
  1,
  1,
  3,
  1,
  1,
  2,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  2,
  2,
  2,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  2,
  1,
  2,
  2,
  1,
  1,
  1,
  1,
  2,
  2,
  2,
  2,
  1,
  1,
  1,
  1,
  2,
  1,
  1,
  2,
  1,
  2,
  1,
  2,
  3,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  6,
  2,
  1,
  1,
  1,
  1,
  1,
  3,
  2,
  1,
  2,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  4,
  4,
  1,
  2,
  1,

]


epochs_dec: 50
epochs_dec_elem: 10 ###
lr_DEC_opt: 0.0005
lr_DEC_SGD: 0.01